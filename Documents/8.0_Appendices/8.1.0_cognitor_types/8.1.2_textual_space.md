# Textual Space 中的 Cognitors 属性

> 基于 [[8.1.1_introduction]] [[1.1.1_protocol_requirements]]

ACP Textual Space 在当前章节中简称为 Space。

## 1. 人类 (Human)

### 1.1 定义

指生物学意义上的自然人，且拥有内在的、完整的自然认知能力体系。

### 1.2 核心特性

#### 1.2.1 原生认知

天然具备学习、推理、元认知、创造力、常识、情感、意图和社会智能。

#### 1.2.2 原生记忆

具有连续、跨场景的**持久性记忆系统**，包括：

- **跨Space记忆保留**：可自然保持对多个独立`Space`交互历史的记忆。
- **经验累积**：能主动关联不同`Space`中的知识片段形成认知网络。
- **元记忆能力**：对自身记忆的完整性、准确度具有评估能力。

#### 1.2.3 具身能力 (Embodied Capability)

- **物理交互能力**: 可直接操控现实世界（如操作设备、调整环境、执行实验），而不仅限于符号层面的计算。
- **多模态感知**: 通过视觉、听觉、触觉、嗅觉等感官实时获取信息，并动态调整认知策略。
- **即时反馈调整**: 能在现实交互中实时修正行为（如调试代码、调整实验参数），而非仅依赖预定义的认知轨迹回溯。
- **主观能动性**: 可自主决定何时、如何介入 ACP 交互（如主动退出 Space、修改上下文、引入外部数据）。
- **跨媒介执行**: 能同时在 `Space` 和物理世界（实验室、社交环境）中协调任务。

#### 1.2.4 深度情境理解

擅长理解隐含意义、语用和复杂上下文。

#### 1.2.5 主观性与能动性

拥有意识、主观体验和内在驱动力。

#### 1.2.6 具身与社会性

认知受物理身体和社会环境影响。

### 1.3 局限性

人类作为 Cognitor 在 Space 中的局限性包括：

#### 1.3.1 认知局限

- 受限于**注意力**、当前**知识范围**和**信息处理速度**，难以处理海量或高复杂度信息。
- 可能受**偏见**、**情绪**和**先有经验**影响，导致判断失误或视野狭窄。
- 容易受到**外部干扰**或自身状态（如疲劳、压力）影响而**分心**，导致任务中断或偏离。
- 对许多使用的符号（语言、数学符号、抽象概念如“正义”、“自由”、“爱”等）的理解，并非直接对应于可触摸或看到的具体物体，而是通过文化共识、定义、经验的关联以及在特定语境中的使用来建立的。不同文化、不同个体对同一抽象符号的理解可能存在差异。
- 对世界的学习和理解，很大一部分是通过语言、书籍、图像、视频等符号系统传递的间接经验。理解的准确性和深度取决于符号系统的质量、传递者的意图以及接收者的解读能力。如果符号系统存在偏差或信息不完整，理解也会出现偏差。
- 试图用语言（符号）来表达内在的主观体验，例如感受、情绪、意识等等，但语言本身是有限的，难以完全捕捉和传递这些主观体验的丰富性和复杂性。个体描述感受可能与他人理解的不同，因为个人经历和感受不同。
- 由于不同的文化和语言使用不同的符号系统来指代世界和概念，一个符号在一个文化中可能具有明确的意义，但在另一个文化中可能完全不同或不存在对应的概念。
- 记忆和认知过程并非完美，会受到各种偏差的影响。对过去的事件的符号化回忆可能会失真或被重构。对世界的理解也会受到先验知识、信念和偏见的影响，导致对新信息的解读产生偏差。

#### 1.3.2 精力与时间限制

- 需要**休息**，无法进行不间断、高强度的持续工作，容易**疲劳**。
- 同一时间只能处理有限的任务，**多任务处理能力有限**。

#### 1.3.3 行为惰性与非理性

- 可能表现出**懒惰**、**拖延**，规避复杂或重复性任务。
- 可能因**厌烦**、**挫败感**等情绪而放弃或**抵触**交互。
- 可能过度依赖自动化或AI，**减少自主思考或验证**。

#### 1.3.4 易出错性

- 在输入、逻辑推理、数据解读或操作过程中容易**犯错**。
- **记忆不完美**，会随时间衰退，且可能遗忘或混淆细节。

### 1.4 在 ACP 中的角色

* 典型的交互**发起者、指令者、评估者和最终解释者**。
* 可以作为**协作者**与其他 `Cognitor` 合作。
* 可以**扮演角色**，即作为 `PersonaCognitor` 的扮演者。
* 通常拥有对 ACP 环境的元认知理解和控制权（如开发者）。
* **物理世界锚点**: 通常，人类是 ACP Textual Space 与真实世界的**唯一天然桥梁**，例如：
    * 将实验数据手动录入 Space。
    * 根据现实反馈修正 `Object` 的约束条件。
    * 真实执行代码
* **协议弹性维护者**: 当 LLM Agent 陷入逻辑循环或知识盲区时，人类可通过具身行动打破僵局（如实地调查补充数据）。
* 有时可以**修改上下文**，例如，人类可以直接修改已有的 `Canvas` 中的某个 `ct` 节点，来控制 `LLM Agent` 的行为。

### 1.5 认知轨迹与透明性

* 核心认知过程内在。在标准交互中通常不强制要求详细的外显认知轨迹，其元认知通过行为、反馈或显式沟通体现。协议不排除在特定高透明度协作场景下要求人类记录决策过程的可能性。

## 2. LLM Agent (大型语言模型代理)

### 2.1 定义

* 指主要由大型语言模型（LLM）驱动，并展现出**通用目的、通常被设定为中立或助手形象、未经高度个性化角色深度定制**的认知实体。

### 2.2 核心特性

* **数据驱动与通用性**: 其知识和行为主要反映底层 LLM 的训练数据和通用能力。
* **语言中心**: 高度擅长自然语言理解与创建。
* **直接访问模型能力**: 通常被视为直接调用底层 LLM 通用能力的接口。
* **有限的角色扮演**: 默认不被要求严格维持一个狭义的、高度个性化的角色，其"个性"通常是通用、中立或助手式的。通常作为一种“搜索引擎”，仅为了回答问题。

### 2.3 局限性

#### 2.3.1 固有限制

继承 LLM 的固有局限：

- **知识截止**：由于模型基于特定时间点的数据进行训练，因此对于该时间点之后的信息和事件缺乏了解。
- **幻觉**：指LLM生成的内容可能包含不准确、虚构或者与现实不符的信息。这通常发生在处理复杂问题或超出其训练数据范围的话题时。
- **符号接地问题**：LLM 无法感知到名词的**对象(Object)**。这意味着它们可能无法正确地将语言中的概念与真实世界的现象对应起来。
- **逻辑推理限制**：尽管LLM可以执行一定程度的逻辑推理任务，但当涉及深层次或多步骤的逻辑分析时，可能会出现错误或不一致的结果。
- **文化偏差**：由于训练数据集的局限性，LLM可能会体现出一定的文化偏见，对某些群体或文化的表现可能存在刻板印象或误解。
- **领域专精度不足**：在一些专业领域内，如医学、法律等，由于相关术语和知识的专业性较强，LLM可能无法提供足够准确的回答或建议。
- **不可控输出**：虽然可以通过调整输入（如提示设计）来引导LLM的行为，但是其输出仍然具有一定的随机性和不确定性，尤其是在开放式的对话环境中。
- **伦理与安全挑战**：存在潜在风险，包括但不限于生成有害内容、隐私泄露以及难以确保对话内容符合社会伦理标准等问题。

#### 2.3.2 记忆局限性

- **会话隔离性**：每个`Space`实例形成独立的记忆边界，无法直接跨`Space`传递信息。
- **临时记忆**：仅在当前交互会话中保持上下文记忆（受限于token窗口）。
- **无持久状态**：不同`Space`中的LLM实例互不知晓彼此的存在与活动。
- **知识固化**：依赖预训练参数存储的静态知识，难以自主更新长期记忆。

### 2.4 补偿机制

- 必须通过CT系统完整记录当前`Space`内的认知过程。
- 依赖人类或其他拥有所需能力的`Cognitor`主动进行跨`Space`的知识同步。
- 可通过人类来实际运行代码或其它现实交互。
- 可能可通过 “Tool Use / Function Calling” 来实际运行代码或其它现实交互。
- 可通过跨认知实体执行委托或工具调用（如果有）来缓解**知识截止**和**会话隔离性**。
- 需通过CT系统来增加识别**幻觉**的可能性。
- 通过更大的模型和更多的数据可以一定程度缓解**符号接地问题**。
- 需通过CT系统来进行深度**逻辑推理**。
- 需通过CT系统来识别**文化偏差**。
- 越先进的模型的领域专精度能力越高，可以缓解**领域专精度不足**。
- 需精细设定CT系统的结构，并设定期望输出来缓解**不可控输出**。
- 对**伦理与安全挑战**的应对取决于对风险的定义和接受程度。

### 2.5 在 ACP 中的角色

* 通用的信息提供者和任务执行者。
* 可以作为驱动 `PersonaCognitor` 的基础引擎。

### 2.6 认知轨迹与透明性

- LLM Agent 的**核心认知过程**（即底层模型的计算、权重激活等）是**内在**且**黑箱化**的。
- 然而，为了满足 ACP 框架对透明性、可追溯性和协作的需求，在标准交互流程中，**强制要求** LLM Agent **外显地输出**其**详细的认知轨迹**。
- 这里的“外显认知轨迹”并**不是**指底层的神经网络计算细节，而是指 LLM Agent 根据其接收到的输入和内部状态，**生成并呈现**的、能够体现其**推理步骤、中间思考过程、信息处理逻辑或决策路径**的文本或结构化数据。例如，“链式思考 (Chain-of-Thought)”、“scratchpad” 中的中间步骤、分解任务的过程等。这需要设计CT系统的结构。
- LLM Agent 的“元认知”（对自身思考过程或状态的模拟性评估）主要通过这种外显的认知轨迹、其产生的行为结果、提供的反馈信息以及其显式的沟通过程本身来体现。
- 这项强制要求确保了 LLM Agent 的工作过程对 ACP 系统中的其他参与者（特别是人类）是**可见且可理解**的，便于审查、调试、纠错或进行更深度的协作。

## 3. PersonaCognitor (角色认知体)

### 3.1 定义

* 指被**显式设计或主动扮演**成具有**特定、明确的角色、个性或人物形象**的认知实体。其核心在于**优先模拟或展现该特定身份**的行为模式、语言风格、知识范围和可能的互动倾向。其认知对扮演者完全透明。

### 3.2 与 LLM Agent 的区分

* 虽然底层的 AI `PersonaCognitor` 可能由 `LLM Agent` 驱动，但 `PersonaCognitor` 的关键在于其行为**以服务于特定角色设定为首要目标**，可能对其底层通用能力进行筛选、调整或覆盖，以保持角色一致性。与 `LLM Agent` 的通用性相对，`PersonaCognitor` 强调的是**角色的特殊性**。

### 3.3 核心特性

* **角色中心**: 行为高度受角色设定约束。
* **个性化与风格化**: 展现鲜明、一致的个性、语言风格或情感倾向。
* **特定知识/视角模拟**: 可能模拟特定专家、虚构人物、或代表某种特定立场/功能。
* **实现载体多样**: 可以由 `LLM Agent` 模拟，也可以由**人类**扮演。
* **交互引导**: 常用于引导特定类型的交互（如教学、娱乐、限定特定领域知识）。

### 3.4 在 ACP 中的角色

* **定制化的交互界面/伙伴**: 提供更自然、更有吸引力或更符合场景需求的互动。
* **模拟与训练环境中的角色**: 扮演特定 NPC、对手或导师。
* **特定功能代理**: 如项目协调员、领域专家助手等拟人化代理。
* **视角转换**: 如扮演不同语言的使用者来使用不同的思考方式。

### 3.5 认知轨迹与透明性

* 取决于实现载体。AI 驱动的可能记录维持角色的过程；人类扮演的遵循人类认知轨迹习惯。`CognitorInfo` 中应清晰描述其扮演的角色、核心个性及实现载体（AI/人类）。

### 3.6 扮演者唯一性

* 通常在同一个时刻，一个 `PersonaCognitor` 只能由一个 `Cognitor` 扮演。切换扮演者需要在Space中显式声明。