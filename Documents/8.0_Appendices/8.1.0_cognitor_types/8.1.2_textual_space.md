# Textual Space 中的 Cognitors 属性

> 基于 [[8.1.1_introduction]] [[1.1.1_protocol_requirements]]

ACP Textual Space 在当前章节中简称为 Space。

## 1. 人类 (Human)

### 1.1 定义

指生物学意义上的自然人，且拥有内在的、完整的自然认知能力体系。

### 1.2 核心特性

#### 1.2.1 原生认知

天然具备学习、推理、元认知、创造力、常识、情感、意图和社会智能。

#### 1.2.2 原生记忆

具有连续、跨场景的**持久性记忆系统**，包括：

- **跨Space记忆保留**：可自然保持对多个独立`Space`交互历史的记忆。
- **经验累积**：能主动关联不同`Space`中的知识片段形成认知网络。
- **元记忆能力**：对自身记忆的完整性、准确度具有评估能力。

#### 1.2.3 具身能力 (Embodied Capability)

- **物理交互能力**: 可直接操控现实世界（如操作设备、调整环境、执行实验），而不仅限于符号层面的计算。
- **多模态感知**: 通过视觉、听觉、触觉、嗅觉等感官实时获取信息，并动态调整认知策略。
- **即时反馈调整**: 能在现实交互中实时修正行为（如调试代码、调整实验参数），而非仅依赖预定义的认知轨迹回溯。
- **主观能动性**: 可自主决定何时、如何介入 ACP 交互（如主动退出 Space、修改上下文、引入外部数据）。
- **跨媒介执行**: 能同时在 `Space` 和物理世界（实验室、社交环境）中协调任务。

#### 1.2.4 深度情境理解

擅长理解隐含意义、语用和复杂上下文。

#### 1.2.5 主观性与能动性

拥有意识、主观体验和内在驱动力。

#### 1.2.6 具身与社会性

认知受物理身体和社会环境影响。

### 1.3 局限性

人类作为 Cognitor 在 Space 中的局限性包括：

#### 1.3.1 认知局限

* 受限于**注意力**、当前**知识范围**和**信息处理速度**，难以处理海量或高复杂度信息。
* 可能受**偏见**、**情绪**和**先有经验**影响，导致判断失误或视野狭窄。
* 容易受到**外部干扰**或自身状态（如疲劳、压力）影响而**分心**，导致任务中断或偏离。

#### 1.3.2 精力与时间限制

* 需要**休息**，无法进行不间断、高强度的持续工作，容易**疲劳**。
* 同一时间只能处理有限的任务，**多任务处理能力有限**。

#### 1.3.3 行为惰性与非理性

* 可能表现出**懒惰**、**拖延**，规避复杂或重复性任务。
* 可能因**厌烦**、**挫败感**等情绪而放弃或**抵触**交互。
* 可能过度依赖自动化或AI，**减少自主思考或验证**。

#### 1.3.4 易出错性

* 在输入、逻辑推理、数据解读或操作过程中容易**犯错**。
* **记忆不完美**，会随时间衰退，且可能遗忘或混淆细节。

### 1.4 在 ACP 中的角色

* 典型的交互**发起者、指令者、评估者和最终解释者**。
* 可以作为**协作者**与其他 `Cognitor` 合作。
* 可以**扮演角色**，即作为 `PersonaCognitor` 的扮演者。
* 通常可以**修改上下文**，例如，人类可以直接修改已有的 `Canvas` 中的某个 `ct` 节点，来控制 `LLM Agent` 的行为。
* 通常拥有对 ACP 环境的元认知理解和控制权（如开发者）。
* **物理世界锚点**: 通常，人类是 ACP Textual Space 与真实世界的**唯一天然桥梁**，例如：
    * 将实验数据手动录入 Space。
    * 根据现实反馈修正 `Object` 的约束条件。
* **协议弹性维护者**: 当 LLM Agent 陷入逻辑循环或知识盲区时，人类可通过具身行动打破僵局（如实地调查补充数据）。

### 1.5 认知轨迹与透明性

* 核心认知过程内在。在标准交互中通常不强制要求详细的外显认知轨迹，其元认知通过行为、反馈或显式沟通体现。协议不排除在特定高透明度协作场景下要求人类记录决策过程的可能性。

## 2. LLM Agent (大型语言模型代理)

### 2.1 定义

* 指主要由大型语言模型（LLM）驱动，并展现出**通用目的、通常被设定为中立或助手形象、未经高度个性化角色深度定制**的认知实体。

### 2.2 核心特性

* **数据驱动与通用性**: 其知识和行为主要反映底层 LLM 的训练数据和通用能力。
* **语言中心**: 高度擅长自然语言理解与创建。
* **直接访问模型能力**: 通常被视为直接调用底层 LLM 通用能力的接口。
* **有限的角色扮演**: 默认不被要求严格维持一个狭义的、高度个性化的角色，其"个性"通常是通用、中立或助手式的。通常作为一种“搜索引擎”，仅为了回答问题。

### 2.3 局限性

#### 2.3.1 固有限制

* 继承 LLM 的固有局限，如幻觉、知识截止等。

#### 2.3.2 记忆局限性

* **会话隔离性**：每个`Space`实例形成独立的记忆边界，无法直接跨`Space`传递信息。
* **临时记忆**：仅在当前交互会话中保持上下文记忆（受限于token窗口）。
* **无持久状态**：不同`Space`中的LLM实例互不知晓彼此的存在与活动。
* **知识固化**：依赖预训练参数存储的静态知识，难以自主更新长期记忆。

### 2.4 补偿机制

* 必须通过认知轨迹系统完整记录当前`Space`内的认知过程。
* 依赖人类或其他拥有所需能力的`Cognitor`主动进行跨`Space`的知识同步。
* 可通过人类来实际运行代码或其它现实交互。
* 可能可通过 “Tool Use / Function Calling” 来实际运行代码或其它现实交互。

### 2.5 在 ACP 中的角色

* 常见的 `Space` 实现者和协调者。
* 通用的信息提供者和任务执行者。
* 可以作为驱动 `PersonaCognitor` 的基础引擎。

### 2.6 认知轨迹与透明性

- LLM Agent 的**核心认知过程**（即底层模型的计算、权重激活等）是**内在**且**黑箱化**的。
- 然而，为了满足 ACP 框架对透明性、可追溯性和协作的需求，在标准交互流程中，**强制要求** LLM Agent **外显地输出**其**详细的认知轨迹**。
- 这里的“外显认知轨迹”并**不是**指底层的神经网络计算细节，而是指 LLM Agent 根据其接收到的输入和内部状态，**生成并呈现**的、能够体现其**推理步骤、中间思考过程、信息处理逻辑或决策路径**的文本或结构化数据。例如，“链式思考 (Chain-of-Thought)”、“scratchpad” 中的中间步骤、分解任务的过程等。
- LLM Agent 的“元认知”（对自身思考过程或状态的模拟性评估）主要通过这种外显的认知轨迹、其产生的行为结果、提供的反馈信息以及其显式的沟通过程本身来体现。
- 这项强制要求确保了 LLM Agent 的工作过程对 ACP 系统中的其他参与者（特别是人类）是**可见且可理解**的，便于审查、调试、纠错或进行更深度的协作。

## 3. PersonaCognitor (角色认知体)

### 3.1 定义

* 指被**显式设计或主动扮演**成具有**特定、明确的角色、个性或人物形象**的认知实体。其核心在于**优先模拟或展现该特定身份**的行为模式、语言风格、知识范围和可能的互动倾向。其认知对扮演者完全透明。

### 3.2 与 LLM Agent 的区分

* 虽然底层的 AI `PersonaCognitor` 可能由 `LLM Agent` 驱动，但 `PersonaCognitor` 的关键在于其行为**以服务于特定角色设定为首要目标**，可能对其底层通用能力进行筛选、调整或覆盖，以保持角色一致性。与 `LLM Agent` 的通用性相对，`PersonaCognitor` 强调的是**角色的特殊性**。

### 3.3 核心特性

* **角色中心**: 行为高度受角色设定约束。
* **个性化与风格化**: 展现鲜明、一致的个性、语言风格或情感倾向。
* **特定知识/视角模拟**: 可能模拟特定专家、虚构人物、或代表某种特定立场/功能。
* **实现载体多样**: 可以由 `LLM Agent` 模拟，也可以由**人类**扮演。
* **交互引导**: 常用于引导特定类型的交互（如教学、娱乐、限定特定领域知识）。

### 3.4 在 ACP 中的角色

* **定制化的交互界面/伙伴**: 提供更自然、更有吸引力或更符合场景需求的互动。
* **模拟与训练环境中的角色**: 扮演特定 NPC、对手或导师。
* **特定功能代理**: 如项目协调员、领域专家助手等拟人化代理。

### 3.5 认知轨迹与透明性

* 取决于实现载体。AI 驱动的可能记录维持角色的过程；人类扮演的遵循人类认知轨迹习惯。`CognitorInfo` 中应清晰描述其扮演的角色、核心个性及实现载体（AI/人类）。

### 3.6 扮演者唯一性

* 通常在同一个时刻，一个 `PersonaCognitor` 只能由一个 `Cognitor` 扮演。切换扮演者需要在认知轨迹中显式声明。