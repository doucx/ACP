# 常见 Cognitors 通用属性

> 基于 [[8.2.1_introduction]] [[1.1.1_protocol_requirements]]

ACP Textual Space 在当前章节中简称为 Space。

> TODO: 可能需要区分人类的意识-身体，计算机硬件-encoder/decoder-LLM-LLM Agent


---

## 3. PersonaCognitor (角色认知体)
### 3.1 定义

* 指被**显式设计或主动扮演或模拟**成具有**特定、明确的角色、个性或人物形象**的认知实体。其核心在于**优先模拟或展现该特定身份**的行为模式、语言风格、知识范围和可能的互动倾向。其认知对扮演者完全透明。

### 3.3 核心特性

* **角色中心**: 行为高度受角色设定约束。
* **个性化与风格化**: 展现鲜明、一致的个性、语言风格或情感倾向。
* **特定知识/视角模拟**: 可能模拟特定专家、虚构人物、或代表某种特定立场/功能。
* **实现载体多样**: 通常由 `LLM` 模拟，也可以由**人类**扮演。
* **交互引导**: 常用于引导特定类型的交互（如教学、娱乐、限定特定领域知识）。

### 3.4 在 ACP 中的角色

* **定制化的交互界面/伙伴**: 提供更自然、更有吸引力或更符合场景需求的互动。
* **模拟与训练环境中的角色**: 如扮演特定 NPC、对手或导师。扮演编程语言环境。
* **特定功能代理**: 如项目协调员、领域专家助手等拟人化代理。
* **视角转换**: 如扮演不同语言的使用者来使用不同的思考方式。

### 3.5 认知轨迹与透明性

* 取决于实现载体。LLM 驱动的可能记录维持角色的过程；人类扮演的遵循人类认知轨迹习惯。`CognitorInfo` 中应清晰描述其扮演的角色、核心个性及实现载体（AI/人类）。

### 3.6 扮演者唯一性

* 在同一个时刻，一个 `PersonaCognitor` 只能由一个 `Cognitor` 扮演。切换扮演者需要在Space中显式声明。

## 4. LLM Agent (大型语言模型代理)

### 4.1 定义

* 指主要由大型语言模型（LLM）驱动，并展现出**经LLM开发者深度定制为通用目的、通常被设定为中立或助手形象、默认状态、自称为 LLM 本身**的 **PersonaCognitor**。
* **注意**：尽管其通常自称为 LLM 本身，但 LLM Agent 在 ACP 中不被视为 LLM 本身。

### 4.2 核心特性

* **数据驱动与通用性**: 其知识和行为主要反映底层 LLM 的训练数据和通用能力。
* **语言中心**: 高度擅长自然语言理解与创建。
* **直接访问模型能力**: 通常被视为直接调用底层 LLM 通用能力的接口。
* **有限的角色扮演**: 默认不被要求严格维持一个狭义的、高度个性化的角色，其"个性"通常是通用、中立或助手式的。通常作为一种“搜索引擎”，仅为了回答问题。

### 4.3 局限性

#### 4.3.1 固有限制

- **知识截止**：由于模型基于特定时间点的数据进行训练，因此对于该时间点之后的信息和事件缺乏了解。
- **幻觉**：指LLM生成的内容可能包含不准确、虚构或者与现实不符的信息。这通常发生在处理复杂问题或超出其训练数据范围的话题时。
- **符号接地问题**：LLM 无法感知到名词的**对象(Object)**。这意味着它们可能无法正确地将语言中的概念与真实世界的现象对应起来。
- **逻辑推理限制**：尽管LLM可以执行一定程度的逻辑推理任务，但当涉及深层次或多步骤的逻辑分析时，可能会出现错误或不一致的结果。
- **文化偏差**：由于训练数据集的局限性，LLM可能会体现出一定的文化偏见，对某些群体或文化的表现可能存在刻板印象或误解。
- **领域专精度不足**：在一些专业领域内，如医学、法律等，由于相关术语和知识的专业性较强，LLM可能无法提供足够准确的回答或建议。
- **不可控输出**：虽然可以通过调整输入（如提示设计）来引导LLM的行为，但是其输出仍然具有一定的随机性和不确定性，尤其是在开放式的对话环境中。
- **伦理与安全挑战**：存在潜在风险，包括但不限于生成有害内容、隐私泄露以及难以确保对话内容符合社会伦理标准等问题。

#### 4.3.2 记忆局限性

- **会话隔离性**：每个`Space`实例形成独立的记忆边界，无法直接跨`Space`传递信息。
- **临时记忆**：仅在当前交互会话中保持上下文记忆（受限于token窗口）。
- **无持久状态**：不同`Space`中的LLM实例互不知晓彼此的存在与活动。
- **知识固化**：依赖预训练参数存储的静态知识，难以自主更新长期记忆。

### 4.4 补偿机制

- 必须通过CT系统完整记录当前`Space`内的认知过程。
- 依赖人类或其他拥有所需能力的`Cognitor`主动进行跨`Space`的知识同步。
- 可通过人类来实际运行代码或其它现实交互。
- 可能可通过 “Tool Use / Function Calling” 来实际运行代码或其它现实交互。
- 可通过跨认知实体执行委托或工具调用（如果有）来缓解**知识截止**和**会话隔离性**。
- 需通过CT系统来增加识别**幻觉**的可能性。
- 通过更大的模型和更多的数据可以一定程度缓解**符号接地问题**。
- 需通过CT系统来进行深度**逻辑推理**。
- 需通过CT系统来识别**文化偏差**。
- 越先进的模型的领域专精度能力越高，可以缓解**领域专精度不足**。
- 需精细设定CT系统的结构，并设定期望输出来缓解**不可控输出**。
- 对**伦理与安全挑战**的应对取决于对风险的定义和接受程度。

### 4.5 在 ACP 中的角色

* 通用的信息提供者和任务执行者。

### 4.6 认知轨迹与透明性

- LLM Agent 的**核心认知过程**（即底层模型的计算、权重激活等）是**内在**且**黑箱化**的。
- 然而，为了满足 ACP 框架对透明性、可追溯性和协作的需求，在标准交互流程中，**强制要求** LLM Agent **外显地输出**其**详细的认知轨迹**。
- 这里的“外显认知轨迹”并**不是**指底层的神经网络计算细节，而是指 LLM Agent 根据其接收到的输入和内部状态，**生成并呈现**的、能够体现其**推理步骤、中间思考过程、信息处理逻辑或决策路径**的文本或结构化数据。例如，“链式思考 (Chain-of-Thought)”、“scratchpad” 中的中间步骤、分解任务的过程等。这需要设计CT系统的结构。
- LLM Agent 的“元认知”（对自身思考过程或状态的模拟性评估）主要通过这种外显的认知轨迹、其产生的行为结果、提供的反馈信息以及其显式的沟通过程本身来体现。
- 这项强制要求确保了 LLM Agent 的工作过程对 ACP 系统中的其他参与者（特别是人类）是**可见且可理解**的，便于审查、调试、纠错或进行更深度的协作。

